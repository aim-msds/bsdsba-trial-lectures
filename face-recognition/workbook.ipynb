{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e9ffa0",
   "metadata": {},
   "source": [
    "# Facial Recognition Workbook <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ede46",
   "metadata": {},
   "source": [
    "It's time to get your hands dirty and create your own facial recognition model using your own dataset!\n",
    "\n",
    "Form a group of two or three people then use this workbook to generate interesting insights such as:\n",
    "\n",
    "1. Based from the eigenfaces, what facial features can you look at to distinguish the face each member of your group effectively?\n",
    "2. Which among your parents do you look alike the most?\n",
    "3. Which among your newfound friends/future classmate do you look alike the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f26480",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288e4fb",
   "metadata": {},
   "source": [
    "Step 0: Uncomment the cell below to prepare the folders and cascade model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !mkdir data/raw\n",
    "# !wget https://raw.githubusercontent.com/aim-msds/bsdsba-trial-lectures/main/face-recognition/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c14debc",
   "metadata": {},
   "source": [
    "### Image Uploading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724aae6",
   "metadata": {},
   "source": [
    "Step 1: Upload pictures on the `data/raw` folder which you will use as your dataset to compute for the principal components and eigenfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643d866",
   "metadata": {},
   "source": [
    "### Face detection and image cropping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c39ad28",
   "metadata": {},
   "source": [
    "Step 2: Execute the pipeline below to automatically crop face images from the uploaded raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66455ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T15:58:13.312312Z",
     "start_time": "2023-03-10T15:58:13.067987Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and filepaths\n",
    "RAW_DIRPATH = './data/raw'\n",
    "CASCADE_MODEL_FILEPATH = './haarcascade_frontalface_default.xml'\n",
    "OUTPUT_DIRPATH = './data/processed'\n",
    "\n",
    "# Model settings\n",
    "scaleFactor = 1.2\n",
    "minNeighbors = 5\n",
    "minSize = (30, 30)\n",
    "outputSize = (128, 128)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIRPATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fe4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the filepaths of images in the raw directory path\n",
    "image_filepaths = sorted(glob(RAW_DIRPATH + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee488880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our face detector model\n",
    "cascade_model = cv2.CascadeClassifier(CASCADE_MODEL_FILEPATH)\n",
    "\n",
    "# Iterate on to the images found in the RAW_DIRPATH folder\n",
    "for i, image_filepath in enumerate(image_filepaths):\n",
    "    # Read the image and convert to gray scale\n",
    "    image = cv2.imread(image_filepath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get the detected faces using the model with specified settings\n",
    "    faces = cascade_model.detectMultiScale(\n",
    "        gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors,\n",
    "        minSize=minSize, flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Iterate on each detected faces, crop, then save the cropped image\n",
    "    # onto an output directory\n",
    "    for j, (x, y, width, height) in enumerate(faces):\n",
    "        cropped_image = gray[y:y + height, x:x + width]\n",
    "        cropped_resized = cv2.resize(cropped_image, outputSize)\n",
    "        output_filepath = os.path.join(OUTPUT_DIRPATH, f'{i +1 :02}-{j + 1:02}.jpg')\n",
    "        cv2.imwrite(output_filepath, cropped_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940eb1aa",
   "metadata": {},
   "source": [
    "Step 3: Check the processed folder and ensure that they are clean and contain only cropped face images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd52519",
   "metadata": {},
   "source": [
    "### Creating the data matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45594829",
   "metadata": {},
   "source": [
    "Step 4: Create the data matrix by reading each cropped faces in the processed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIRPATH = './data/processed'\n",
    "processed_image_filepaths = sorted(glob(PROCESSED_DIRPATH + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for image_filepath in processed_image_filepaths:\n",
    "    cur_image = cv2.imread(image_filepath, cv2.IMREAD_GRAYSCALE) / 255.\n",
    "    cur_image = cur_image.flatten()\n",
    "    data.append(cur_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9bc11",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285bc7f",
   "metadata": {},
   "source": [
    "Step 5: Compute for the principal components of the dataset using `PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96243992",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(len(data), random_state=1337)\n",
    "\n",
    "reduced_data = pca.fit_transform(data)\n",
    "principal_components = pca.components_\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5740b",
   "metadata": {},
   "source": [
    "Step 6: Plot the eigenfaces then interpret the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0941b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T16:46:38.700230Z",
     "start_time": "2023-03-10T16:46:38.125579Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_eigenfaces(\n",
    "    principal_components, explained_variance, num_components_to_plot=10,\n",
    "    figsize=(16, 6)):\n",
    "    \"\"\"Plot the eigenface annotated with their corresponding explained\n",
    "    variance\n",
    "    \"\"\"\n",
    "    num_columns = 5\n",
    "    num_rows = num_components_to_plot // num_columns\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=figsize)\n",
    "\n",
    "    for i in range(num_components_to_plot):\n",
    "        ax = axes.flatten()[i]\n",
    "        cur_component = abs(principal_components[i, :])\n",
    "        cur_explained_variance = round(explained_variance[i] * 100, 2)\n",
    "        img_dim = int(np.sqrt(len(cur_component)))\n",
    "        cur_component = cur_component.reshape((img_dim, img_dim))\n",
    "        ax.imshow(cur_component)\n",
    "        ax.set_title(f\"PCA {i + 1} ({cur_explained_variance}%)\", fontsize=12, weight='bold')\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eigenfaces(principal_components, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b1182",
   "metadata": {},
   "source": [
    "## Facial Recognition Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "class FacialRecognitionModel:\n",
    "    \"\"\"A machine learning model that predicts which face a given test\n",
    "    input is based on reference images\n",
    "    \"\"\"\n",
    "    def __init__(self, ref_images, pca):\n",
    "        \"\"\"Initialize the facial recognition model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ref_images : dict\n",
    "            Dictionary containing the label and image filepath of the\n",
    "            reference images\n",
    "        pca : trained sklearn PCA model\n",
    "            Trained sklearn PCA model using the relevant several images\n",
    "        \"\"\"\n",
    "        # Initialize attributes of this object\n",
    "        self.ref_images = ref_images\n",
    "        self.pca = pca\n",
    "        self.images = {}\n",
    "        self.labels = []\n",
    "        self.pcas = {}\n",
    "\n",
    "        # Generate and compute for the items needed to deploy the model\n",
    "        for label in ref_images:\n",
    "            self.labels.append(label)\n",
    "\n",
    "            # Read image then compute for PCA\n",
    "            image = cv2.imread(ref_images[label], cv2.IMREAD_GRAYSCALE)\n",
    "            image_pca = pca.transform(image.flatten()[np.newaxis, :] / 255.)[0]\n",
    "\n",
    "            # Append the image arrays and computed pca vectors\n",
    "            self.images[label] = image\n",
    "            self.pcas[label] = image_pca\n",
    "\n",
    "    def predict(self, test_image_filepath, metric=cosine):\n",
    "        \"\"\"Predict the label of the test image given its filepath.\n",
    "\n",
    "        Generates the test image along with the prediction annotated\n",
    "        with the distance of the test image with the reference images\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_image_filepath : str or Path\n",
    "            Filepath of the test image\n",
    "        metric : function\n",
    "            Function that takes in two vectors then returns the distance\n",
    "            between two vectors\n",
    "        \"\"\"\n",
    "        # Read the test image and compute for its PCA\n",
    "        test_image = cv2.imread(test_image_filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        test_pca = pca.transform(test_image.flatten()[np.newaxis, :] / 255.)[0]\n",
    "\n",
    "        # Plot the test image\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.imshow(test_image, cmap='gray')\n",
    "        ax.set_title(\"Test image\", fontsize=14, weight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Plot the reference images along with its distance with the\n",
    "        # test image\n",
    "        fig, axes = plt.subplots(1, len(self.images), figsize=(16, 5))\n",
    "\n",
    "        distances = {}\n",
    "        for i, label in enumerate(self.labels):\n",
    "            distance = metric(self.pcas[label], test_pca)\n",
    "            distances[label] = distance\n",
    "\n",
    "            ax = axes.flatten()[i]\n",
    "            ax.imshow(self.images[label], cmap='gray')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"{label} (dist: {distance:0.4f})\", fontsize=14, weight='bold')\n",
    "\n",
    "        prediction = sorted(self.labels, key=lambda x: distances[x])[0]\n",
    "        fig.suptitle(f\"Prediction: {prediction}\", fontsize=16, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdafa09",
   "metadata": {},
   "source": [
    "Step 7: Create a facial recognition model by specifying the image filepaths of your reference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_images = {'Label_1': '<filepath of reference image 1>',\n",
    "              'Label_2': '<filepath of reference image 2>',}\n",
    "\n",
    "model = FacialRecognitionModel(ref_images, pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02ab27",
   "metadata": {},
   "source": [
    "Step 8: Make a prediction on a given test image, evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_filepath = '<filepath of test image>'\n",
    "\n",
    "model.predict(test_image_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-face-recognition]",
   "language": "python",
   "name": "conda-env-.conda-face-recognition-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
